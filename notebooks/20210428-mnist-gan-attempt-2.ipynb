{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_gan import get_root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = get_root_path()\n",
    "DATA_PATH = os.path.join(get_root_path(), \"data\")\n",
    "try: \n",
    "    os.mkdir(DATA_PATH)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 10\n",
    "LATENT_FEATURES = 100\n",
    "\n",
    "_OUT_FEATURES = 1\n",
    "_MNIST_SHAPE = 784\n",
    "\n",
    "GEN_LR = 2e-4\n",
    "DIS_LR = 1e-4\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (0.1307,), (0.3081,)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x*2 - 1.)\n",
    "#     transforms.Normalize(mean=mean, std=std),\n",
    "#     transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=os.path.join(DATA_PATH, \"mnist_data\"), train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=os.path.join(DATA_PATH, \"mnist_data\"), train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "num_batches = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_loader))\n",
    "i = np.random.choice(len(imgs))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.imshow(imgs[i].squeeze(axis=0)*std[0]+mean[0], cmap=\"gray\")\n",
    "ax.set_title(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        negative_slope: float=.2):\n",
    "        super().__init__()       \n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=self.fc1.out_features, out_features=self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(in_features=self.fc2.out_features, out_features=self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(in_features=self.fc3.out_features, out_features=out_features)\n",
    "        self.negative_slope = negative_slope\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=self.negative_slope)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=self.negative_slope)\n",
    "        x = F.leaky_relu(self.fc3(x), negative_slope=self.negative_slope)\n",
    "        return torch.tanh(self.fc4(x))\n",
    "#         return self.fc4(x)\n",
    "            \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int,\n",
    "        out_features: int, \n",
    "        negative_slope: float=.2,\n",
    "        dropout: float=.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=self.fc1.out_features, out_features=self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(in_features=self.fc2.out_features, out_features=self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(in_features=self.fc3.out_features, out_features=1)\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(\n",
    "            F.leaky_relu(self.fc1(x), negative_slope=self.negative_slope),\n",
    "            p=self.dropout)\n",
    "        x = F.dropout(\n",
    "            F.leaky_relu(self.fc2(x), negative_slope=self.negative_slope),\n",
    "            p=self.dropout)\n",
    "        x = F.dropout(\n",
    "            F.leaky_relu(self.fc3(x), negative_slope=self.negative_slope),\n",
    "            p=self.dropout)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(in_features=LATENT_FEATURES, out_features=_MNIST_SHAPE).to(device)\n",
    "D = Discriminator(in_features=_MNIST_SHAPE, out_features=_OUT_FEATURES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "assert G(torch.randn(size=(BATCH_SIZE, LATENT_FEATURES), device=device)).shape == imgs.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "D.eval()\n",
    "assert D(G(torch.randn(size=(BATCH_SIZE, LATENT_FEATURES), device=device))).shape == (BATCH_SIZE, _OUT_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optim = Adam(G.parameters(), lr=GEN_LR)\n",
    "D_optim = Adam(D.parameters(), lr=DIS_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_loss(\n",
    "    y_hat_real: torch.Tensor,\n",
    "    y_hat_fake: torch.Tensor,\n",
    "    epsilon: float=1e-9) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    y_hat_real: torch.Tensor of shape (n, 1)\n",
    "        float values in unconstrained space\n",
    "    \n",
    "    y_hat_fake: torch.Tensor of shape (n, 1)\n",
    "        float values in unconstrained space\n",
    "    \"\"\"\n",
    "    y_hat_real = torch.sigmoid(y_hat_real)\n",
    "    y_hat_fake = torch.sigmoid(y_hat_fake)\n",
    "    \n",
    "    return - torch.mean(\n",
    "        torch.log(y_hat_real + epsilon) \n",
    "        + torch.log(1 - y_hat_fake + epsilon)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_loss(\n",
    "    y_hat_fake: torch.Tensor, \n",
    "    epsilon: float=1e-9) -> float:\n",
    "    \n",
    "    y_hat_fake = torch.sigmoid(y_hat_fake)\n",
    "    return -torch.mean(torch.log(y_hat_fake + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "Z = torch.randn(size=(1, LATENT_FEATURES), device=device)\n",
    "X_fake = G(Z)\n",
    "# Y_hat_fake = D(torch.sigmoid(X_fake))\n",
    "plt.imshow(X_fake.view(28, 28).cpu().detach(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"D\":[], \"G\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(True):\n",
    "    D.train()\n",
    "    G.train()    \n",
    "    t = tqdm(range(100), leave=False)\n",
    "    for i in t:\n",
    "        for j, (X_real, _) in enumerate(train_loader):\n",
    "\n",
    "            # ================= Train Discriminator =======================\n",
    "            X_real = X_real.flatten(start_dim=1).to(device)\n",
    "            Y_hat_real = D(X_real)\n",
    "\n",
    "            Z = torch.randn(size=(len(X_real), LATENT_FEATURES), device=device)\n",
    "            X_fake = G(Z)\n",
    "            Y_hat_fake = D(X_fake)\n",
    "\n",
    "            D_optim.zero_grad()\n",
    "            d_loss = D_loss(y_hat_real=Y_hat_real, y_hat_fake=Y_hat_fake)\n",
    "            d_loss.backward()\n",
    "            D_optim.step()\n",
    "            losses[\"D\"].append(d_loss.item())\n",
    "\n",
    "            # ==================== Train Generator =========================\n",
    "            Z = torch.randn(size=(len(X_real), LATENT_FEATURES), device=device)\n",
    "            X_fake = G(Z)\n",
    "            Y_hat_fake = D(X_fake)\n",
    "\n",
    "            G_optim.zero_grad()\n",
    "            g_loss = G_loss(y_hat_fake=Y_hat_fake)\n",
    "            g_loss.backward()\n",
    "            G_optim.step()\n",
    "            losses[\"G\"].append(g_loss.item())\n",
    "\n",
    "            t.set_description(f\"E: {i}, B: {j}, D: {losses['D'][-1]:.3f}, G: {losses['G'][-1]:.3f}\")\n",
    "            \n",
    "            batches_done = i * num_batches + j\n",
    "            if batches_done % 200 == 0:\n",
    "                save_image(X_fake.data[:25].view(25,1, 28,28), \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist-gan",
   "language": "python",
   "name": "mnist-gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
