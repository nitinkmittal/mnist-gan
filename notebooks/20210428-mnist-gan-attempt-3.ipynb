{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook can be used to understand workflow of GAN to generate MNIST digit images\n",
    "\n",
    "1. Theory: https://www.youtube.com/watch?v=5WoItGTWV54\n",
    "1. Reference: https://github.com/eriklindernoren/PyTorch-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_gan import get_root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = get_root_path()\n",
    "DATA_PATH = os.path.join(get_root_path(), \"data\")\n",
    "RESULT_PATH = os.path.join(get_root_path(), \"images\")\n",
    "\n",
    "try: \n",
    "    \n",
    "    os.makedirs(DATA_PATH, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(RESULT_PATH)\n",
    "    os.makedirs(RESULT_PATH, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "LATENT_FEATURES = 100\n",
    "\n",
    "_OUT_FEATURES = 1\n",
    "MNIST_SHAPE = (28, 28)\n",
    "_mnist_features = np.prod(MNIST_SHAPE)\n",
    "\n",
    "GEN_LR = 2e-4\n",
    "DIS_LR = 1e-4\n",
    "SAMPLE_INTERVAL = 400 # sample generated images after batches\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Note: it is important to scale image pixel values between -1. to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std = (0.1307,), (0.3081,)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert pixel values range to [0.,1.]\n",
    "    transforms.Lambda(lambda x: x*2 - 1.), # convert pixel values range to [-1., 1.]\n",
    "#     transforms.Normalize(mean=mean, std=std),\n",
    "    transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=os.path.join(DATA_PATH, \"mnist_data\"), train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=os.path.join(DATA_PATH, \"mnist_data\"), train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "num_batches = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_loader))\n",
    "i = np.random.choice(len(imgs))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.imshow(imgs[i].view(MNIST_SHAPE), cmap=\"gray\")\n",
    "ax.set_title(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator and Discriminator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        negative_slope: float=.2):\n",
    "        super().__init__()       \n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=256)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=self.fc1.out_features, out_features=self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features=self.fc2.out_features, out_features=self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(\n",
    "            in_features=self.fc3.out_features, out_features=out_features)\n",
    "        self.negative_slope = negative_slope\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=self.negative_slope)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=self.negative_slope)\n",
    "        x = F.leaky_relu(self.fc3(x), negative_slope=self.negative_slope)\n",
    "        return torch.tanh(self.fc4(x)) # tanh will bring values between -1. to 1.\n",
    "            \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int,\n",
    "        out_features: int, \n",
    "        negative_slope: float=.2,\n",
    "        dropout: float=.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=self.fc1.out_features, out_features=self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(in_features=self.fc2.out_features, out_features=self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(in_features=self.fc3.out_features, out_features=1)\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(\n",
    "            F.leaky_relu(self.fc1(x), negative_slope=self.negative_slope),\n",
    "            p=self.dropout)\n",
    "        x = F.dropout(\n",
    "            F.leaky_relu(self.fc2(x), negative_slope=self.negative_slope),\n",
    "            p=self.dropout)\n",
    "        x = F.dropout(\n",
    "            F.leaky_relu(self.fc3(x), negative_slope=self.negative_slope),\n",
    "            p=self.dropout)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(in_features=LATENT_FEATURES, out_features=_mnist_features).to(device)\n",
    "D = Discriminator(in_features=_mnist_features, out_features=_OUT_FEATURES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "assert G(torch.randn(size=(BATCH_SIZE, LATENT_FEATURES), device=device)).shape == imgs.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "D.eval()\n",
    "assert D(G(torch.randn(size=(BATCH_SIZE, LATENT_FEATURES), device=device))).shape == (BATCH_SIZE, _OUT_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optim = Adam(G.parameters(), lr=GEN_LR)\n",
    "D_optim = Adam(D.parameters(), lr=DIS_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_loss(\n",
    "    y_hat_real: torch.Tensor,\n",
    "    y_hat_fake: torch.Tensor,\n",
    "    epsilon: float=1e-9) -> float:\n",
    "    \"\"\"\n",
    "    Return loss for Discrimantor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_hat_real: torch.Tensor of shape (n, 1)\n",
    "        float values in unconstrained space\n",
    "    \n",
    "    y_hat_fake: torch.Tensor of shape (n, 1)\n",
    "        float values in unconstrained space\n",
    "        \n",
    "    epsilon: float, default=1e-9\n",
    "        Adjustment to prevent nan and inf issues.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    loss: float\n",
    "    \"\"\"\n",
    "    y_hat_real = torch.sigmoid(y_hat_real)\n",
    "    y_hat_fake = torch.sigmoid(y_hat_fake)\n",
    "    \n",
    "    return - torch.mean(\n",
    "        torch.log(y_hat_real + epsilon) \n",
    "        + torch.log(1 - y_hat_fake + epsilon)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_loss(\n",
    "    y_hat_fake: torch.Tensor, \n",
    "    epsilon: float=1e-9) -> float:\n",
    "    \"\"\"\n",
    "    Return loss for Generator.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_hat_fake: torch.Tensor of shape (n, 1)\n",
    "        float values in unconstrained space\n",
    "        \n",
    "    epsilon: float, default=1e-9\n",
    "        Adjustment to prevent nan and inf issues.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    loss: float\n",
    "    \"\"\"\n",
    "    y_hat_fake = torch.sigmoid(y_hat_fake)\n",
    "    return - torch.mean(torch.log(y_hat_fake + epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing manual designed loss with built-in torch binary cross entropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real, _ = next(iter(train_loader))\n",
    "X_real = X_real.flatten(start_dim=1).to(device)\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    D.eval()\n",
    "    G.eval()\n",
    "    \n",
    "#     ====================== Discriminator ==========================\n",
    "    Y_hat_real = D(X_real)\n",
    "    real_bce_loss = nn.BCEWithLogitsLoss()(\n",
    "        Y_hat_real, torch.ones((len(X_real), 1), device=device))\n",
    "        \n",
    "    Z = torch.randn(size=(len(X_real), LATENT_FEATURES), device=device)\n",
    "    X_fake = G(Z)\n",
    "    Y_hat_fake = D(X_fake.detach())\n",
    "    fake_bce_loss = nn.BCEWithLogitsLoss()(\n",
    "        Y_hat_fake, torch.zeros((len(X_real), 1), device=device))\n",
    "\n",
    "    assert torch.allclose(real_bce_loss + fake_bce_loss, D_loss(y_hat_real=Y_hat_real, y_hat_fake=Y_hat_fake))    \n",
    "#     ===================== Generator ==========================\n",
    "    X_fake = G(Z)\n",
    "    Y_hat_fake = D(X_fake)\n",
    "    g_bce_loss = nn.BCEWithLogitsLoss()(\n",
    "        Y_hat_fake, torch.ones((len(X_real), 1), device=device))\n",
    "    assert torch.allclose(g_bce_loss, G_loss(y_hat_fake=Y_hat_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"D\":[], \"G\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(True):\n",
    "    D.train()\n",
    "    G.train()    \n",
    "    t = tqdm(range(NUM_EPOCHS), leave=False)\n",
    "    for epoch in t:\n",
    "        for batch_no, (X_real, _) in enumerate(train_loader):\n",
    "            \n",
    "            \n",
    "            # ================= Train Discriminator =======================\n",
    "            Y_real =  torch.ones((len(X_real), 1), device=device)\n",
    "            Y_hat_real = D(X_real.to(device))\n",
    "            \n",
    "            Y_fake =  torch.zeros((len(X_real), 1), device=device)\n",
    "            Z = torch.randn(size=(len(X_real), LATENT_FEATURES), device=device)\n",
    "            X_fake = G(Z)\n",
    "            Y_hat_fake = D(X_fake.detach())\n",
    "\n",
    "            D_optim.zero_grad()\n",
    "            d_loss = D_loss(y_hat_real=Y_hat_real, y_hat_fake=Y_hat_fake)\n",
    "            d_loss.backward()\n",
    "            D_optim.step()\n",
    "            losses[\"D\"].append(d_loss.item())\n",
    "\n",
    "            # ==================== Train Generator =========================\n",
    "            X_fake = G(Z)\n",
    "            Y_hat_fake = D(X_fake)\n",
    "\n",
    "            G_optim.zero_grad()\n",
    "            g_loss = G_loss(Y_hat_fake)\n",
    "            g_loss.backward()\n",
    "            G_optim.step()\n",
    "            losses[\"G\"].append(g_loss.item())\n",
    "\n",
    "            t.set_description(f\"E: {epoch}, B: {batch_no}, D: {losses['D'][-1]:.3f}, G: {losses['G'][-1]:.3f}\")\n",
    "            \n",
    "            num_batches_processed = epoch * num_batches + batch_no\n",
    "            if num_batches_processed % SAMPLE_INTERVAL == 0:\n",
    "                save_image(X_fake.data[:25].view(25, 1, *(MNIST_SHAPE)), f\"{RESULT_PATH}/{num_batches_processed}.png\", nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Lessons:\n",
    "\n",
    "1. Leaky ReLU better than ReLU activation\n",
    "1. Tanh for Generator\n",
    "1. If discriminator learns better than generator then generator would not be able to produce realistic fake image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist-gan",
   "language": "python",
   "name": "mnist-gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
